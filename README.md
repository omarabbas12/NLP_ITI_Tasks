# üß† NLP Projects Collection

This repository contains a series of practical Natural Language Processing (NLP) tasks and research paper summaries designed to reinforce theoretical and applied NLP skills. Each task builds on foundational concepts, ranging from word embeddings to sequence modeling using advanced neural architectures.

## üìÅ Project Structure

### Task 1 ‚Äì Word2Vec Summary
- Summary file: `Omar abbas word2vec summary.txt`
- Overview of the Word2Vec model and its mechanisms, including Skip-gram and CBOW.

### Task 2 ‚Äì CBOW and Skip-gram Implementation
- Notebook: `CBOW_and_Skipgram.ipynb`
- Custom implementation of CBOW and Skip-gram word embedding models using PyTorch or TensorFlow.

### Task 3 ‚Äì Named Entity Recognition (NER)
- Notebook: `NER_using_spacy.ipynb`
- Applying spaCy for NER tasks and visualizing named entities in text data.

### Task 4 ‚Äì NLP Task (unspecified)
- Notebook: `Task_4.ipynb`
- Likely an NLP task involving text classification or preprocessing (please open the notebook for specifics).

### Task 5 ‚Äì Recurrent Neural Networks (RNN)
- Summary: `RNN summary.txt`
- Notebook: `RNN with padding.ipynb`
- Covers handling of sequential data using RNNs, including padding techniques for variable-length sequences.

### Task 6 ‚Äì LSTM and Paper Review
- Folder: `Stacked LSTM/Stacked_LSTM.ipynb`
- Review and experimentation with stacked LSTM layers for sequence modeling tasks.

---

## üìö Research Papers & Summaries

This repository also includes summaries and original papers that were studied:

- **Effective Approaches to Attention-based Neural Machine Translation**
  - Includes: Paper PDF + DOCX Summary

- **Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling**
  - Includes: Paper PDF + RTF Summary

- **NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE**
  - Includes: Paper PDF + DOCX Summary

- **N-ROUGE Metric**  
  - Includes: Summary DOCX describing the ROUGE evaluation metric for NLP tasks

---



